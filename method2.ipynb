{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfe67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "import re\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "import os\n",
    "from db_conn.connection import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rows = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir('./html_source/subchapters'):\n",
    "    title = None\n",
    "    with open(f'./html_source/subchapters/{file_name}', 'rb') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "    try:\n",
    "        title = soup.find('title').text\n",
    "    except:\n",
    "        title = None\n",
    "\n",
    "    for p in soup.find_all('p'):\n",
    "        if p and p.get('class'):\n",
    "            clas = p['class'][0]\n",
    "            html = p\n",
    "        else:\n",
    "            clas = None\n",
    "            html = None\n",
    "\n",
    "        row = pd.DataFrame({\n",
    "            'file_name': [file_name],\n",
    "            'title': [title],\n",
    "            clas: [html]\n",
    "            })\n",
    "        rows.append(row)\n",
    "\n",
    "def batch_concat(dfs, batch_size=10000):\n",
    "    batches = [\n",
    "        pd.concat(dfs[i:i+batch_size], ignore_index=True)\n",
    "        for i in range(0, len(dfs), batch_size)\n",
    "    ]\n",
    "    return pd.concat(batches, ignore_index=True)\n",
    "\n",
    "df = batch_concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460fa091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 s, sys: 441 ms, total: 1.97 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# need to convert to str just for writing to postgres\n",
    "# df.astype(str).replace('nan', None).to_sql('raw_fam_html', engine(), if_exists='replace', index=False)\n",
    "df = pd.read_sql('select * from raw_fam_html', engine())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca90ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1, thresh=10) # Drop columns that have less than 10 non-null values\n",
    "\n",
    "# drop other unneeded columns\n",
    "df = df.drop('FAMTable10pt', axis = 1)\n",
    "df = df.drop('FAMTable10pt3ptBeforeAfter', axis = 1)\n",
    "df = df.drop('MsoFooter', axis = 1)\n",
    "df = df.drop('MsoNormal', axis = 1)\n",
    "df = df.drop('8ptspacer', axis = 1)\n",
    "df = df.drop('FAMBullet', axis = 1)\n",
    "df = df.drop('FAMTableBullet', axis = 1)\n",
    "df = df.drop('HeaderFooterClassificationIndicator', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1312ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_text'] = (\n",
    "    df['FAMBodyTextabc']\n",
    "        .fillna(df['FAMBodyText123'])\n",
    "        .fillna(df['FAMBodyTexta'])\n",
    "        .fillna(df['FAMBodyTextA0'])\n",
    "        .fillna(df['FAMBodyText'])\n",
    "        .fillna(df['FAMBodyText1230'])\n",
    "        .fillna(df['FAMBodyTableText'])\n",
    "        .fillna(df['FAMBodyTexti'])\n",
    "        .fillna(df['FAMBodyBlockquote'])\n",
    "        .fillna(df['TableText11FL'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef772a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['header'] = (\n",
    "        df['FAMHeading20SubchapterNumber']\n",
    "        .fillna(df['FAMHeading20CxSpFirst'])\n",
    "        .fillna(df['FAMHeading20CxSpLast'])\n",
    "        # .fillna(df['FAMCTLineCentered']) fillna with the ctline flush below\n",
    "        .fillna(df['FAMHeading18'])\n",
    "        # .fillna(df['FAMCTLineFlush']) this needs to be a seperate column\n",
    "        .fillna(df['FAMHeading16'])\n",
    "        .fillna(df['FAMHeading14'])\n",
    "        .fillna(df['FAMHeading22'])\n",
    "        .fillna(df['FAMHeading20'])\n",
    "        .fillna(df['FAMHeading20SubchapterNumberCxSpFirst'])\n",
    "        .fillna(df['FAMHeading20SubchapterNumberCxSpLast'])\n",
    "        .fillna(df['FAMHeadingExhibit'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822b7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think its important to parse the html before front filling\n",
    "\n",
    "# Extract the 'a' tag text and remaining 'p' tag text separately\n",
    "def split_p_and_a(html_str):\n",
    "\n",
    "    if html_str:\n",
    "        soup = BeautifulSoup(html_str, 'html')\n",
    "        p = soup.find('p')\n",
    "        \n",
    "        if p:\n",
    "            a_text = p.a.get_text(strip=True) if p.a else None\n",
    "\n",
    "            if p.a:\n",
    "                p.a.extract() # Remove the 'a' tag so only 'p' remains\n",
    "\n",
    "            p_text = p.get_text(strip=True) # Get p text after a is removed\n",
    "\n",
    "            return a_text, p_text\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    return None, None\n",
    "\n",
    "df[['header_a_text', 'header_p_text']] = df['header'].astype(str).apply(lambda x: pd.Series(split_p_and_a(x)))\n",
    "df[['body_a_text', 'body_p_text']] = df['body_text'].astype(str).apply(lambda x: pd.Series(split_p_and_a(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2121a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype(str).replace('nan', None).replace('None', None).to_sql('raw_fam_parsed', engine(), if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out how to not overfill\n",
    "df['FAMHeading20SubchapterNumber'] = df['FAMHeading20SubchapterNumber'].ffill()\n",
    "df['FAMHeading20CxSpFirst'] = df['FAMHeading20CxSpFirst'].ffill()\n",
    "df['FAMHeading20CxSpLast'] = df['FAMHeading20CxSpLast'].ffill()\n",
    "df['FAMCTLineCentered'] = df['FAMCTLineCentered'].ffill()\n",
    "df['FAMHeading18'] = df['FAMHeading18'].ffill()\n",
    "df['FAMCTLineFlush'] = df['FAMCTLineFlush'].ffill()\n",
    "df['FAMHeading16'] = df['FAMHeading16'].ffill()\n",
    "df['FAMHeading14'] = df['FAMHeading14'].ffill()\n",
    "df['FAMHeading22'] = df['FAMHeading22'].ffill()\n",
    "df['FAMHeading20'] = df['FAMHeading20'].ffill()\n",
    "df['FAMHeading20SubchapterNumberCxSpFirst'] = df['FAMHeading20SubchapterNumberCxSpFirst'].ffill()\n",
    "df['FAMHeading20SubchapterNumberCxSpLast'] = df['FAMHeading20SubchapterNumberCxSpLast'].ffill()\n",
    "df['FAMBullet'] = df['FAMBullet'].ffill()\n",
    "df['FAMHeadingExhibit'] = df['FAMHeadingExhibit'].ffill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
